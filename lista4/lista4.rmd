---
title: "MAE0217 - Estatística Descritiva - Lista 4"
author: |
  | Natalia Hitomi Koza\thanks{Número USP: 10698432}
  | Rafael Gonçalves Pereira da Silva\thanks{Número USP: 9009600}
  | Ricardo Geraldes Tolesano\thanks{Número USP: 10734557}
  | Rubens Kushimizo Rodrigues Xavier\thanks{Número USP: 8626718}
  | Rubens Gomes Neto\thanks{Número USP: 9318484}
  | Rubens Santos Andrade Filho\thanks{Número USP: 10370336}
  | Thamires dos Santos Matos\thanks{Número USP: 9402940}
date: "`r stringr::str_to_sentence(format(Sys.time(), '%B de %Y'))`"
lang: pt-BR
header-includes:
  # - \usepackage[brazilian]{babel}
  - \usepackage{float}
  - \usepackage{amsmath}
  - \usepackage{amsthm}
  - \floatplacement{figure}{H}
  - \usepackage{indentfirst}
  - \setlength{\parindent}{4em}
  - \setlength{\parskip}{1em}
  - \usepackage{booktabs}
  - \usepackage{dcolumn}
  - \usepackage{bm}
  - \usepackage{titling}
  - \thanksmarkseries{arabic} % \thanks footnotes com numeros
  - \usepackage[bottom]{footmisc} % corrige posição footnotes
  - \usepackage{pdfpages}
  - \usepackage{tocloft}
  - \renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
  - \usepackage{amssymb}
  - \renewcommand\qedsymbol{$\blacksquare$}
  - \usepackage{pdfpages}
  - \usepackage{cleveref}
  - \usepackage{threeparttable}
output: 
  # pdf_document:
  bookdown::pdf_document2:
    fig_caption: yes
    number_sections: no
    toc: true
    toc_depth: 2
editor_options: 
  chunk_output_type: console
---

\pagebreak

```{r setup, include=FALSE}
options(width = 60)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
library(tidyverse)
library(knitr)
library(readxl)
library(dplyr)
library(patchwork)
library(pander)
library(ggplot2)
library(ggplot)
library(rstatix)
library(ggpubr)
library(car)
library(corrgram)
source('src/helpers.R')
```

## Exercício 1

i)

Tomaremos Volume USG como a variável explicativa x e Peso Real como a variável resposta y. Adotaremos o modelo de regressão linear simples $y_i = \alpha + \beta x_i + e_i$, onde $\alpha$ é o intercepto, $beta$ é a inclinação da reta, e $e_i$ são erros aleatórias não correlacionados.

ii)

```{r}
scatter_title <- "Peso real x volume USG"
scatter_x <- "Volume USG"
scatter_y <- "Peso real"
fit_titles <- list("Resíduos vs observações x para o ajuste feito no modelo",
                    "Gráfico Q-Q normal para o ajuste feito no modelo",
                    "Resíduos normalizados vs observações x para o ajuste feito no modelo",
                    "Resíduos normalizados vs influência das observações para o ajuste feito no modelo")


dados1 <- read_excel("data/peso_volume_figado.xlsx")
dados1 <- dados1[order(dados1$volume_usg), ]
# ggplot(dados, aes(x=volume_usg, y=peso_real)) + geom_point() + geom_smooth(method=lm)
questao_i <- function(dados) {}
ggplot(dados1, aes(x=volume_usg, y=peso_real)) + geom_point() + labs(title=scatter_title, x=scatter_x, y=scatter_y)
```

iii)

Realizaremos o ajuste do modelo e mostraremos algumas métricas de qualidade do modelo:


```{r, fig.height=4}
ajustarModelo <- function(dados) {
  ajuste <- lm(peso_real ~ volume_usg, data=dados)
  intercept <- ajuste$coefficients[1]
  slope <- ajuste$coefficients[2]
  print("O ajuste encontrou os coeficientes:")
  print(paste("Alpha:", intercept))
  print(paste("Beta:", slope))
  p <- ggplot(dados, aes(x=volume_usg, y=peso_real)) + geom_point() + geom_abline(intercept = intercept, slope = slope) + labs(title=scatter_title, x=scatter_x, y=scatter_y)
  plot(p)
  print(summary(ajuste))
  plot(ajuste, 
       caption=fit_titles)
  
  return(ajuste)
}

ajuste <- ajustarModelo(dados1)
```

A análise do ajuste indicou que as observações 3, 11 e 15 são mais influentes no modelo. Em especial, a observação 15 se destaca como outlier em todos os gráficos mostrados. Realizaremos novamente o ajuste com essa observação removida. Não removeremos as observações 3 e 11 dado que possuímos poucas observações e elas não fogem do padrão na mesma intensidade elevada da observação 15.

```{r, fig.height=4}
dados2 <- dados1[-c(15), ]
ajuste <- ajustarModelo(dados2)
```

Observamos uma melhora significativa no valor R^2 após a remoção da observação 15.
Os gráficos indicam que os resíduos possuem os valores dentro do esperado. Idealmente, o R^2 deveria estar próximo de 1, mas não está. Dessa forma, podemos concluir que o ajuste do modelo aproxima os dados, mas não estritamente. Assim, espera-se que o intervalo de confiança ao prever o peso real com base no volume seja grande.

iv)

Construindo intervalos de confiança dos parâmetros:

```{r}
confidence_intervals <- confint(ajuste)
rownames(confidence_intervals) <- c("Alpha", "Beta")
kable(confidence_intervals, caption="Intervalos de confiança para o ajuste dos parâmetros do modelo")
```

v)

A seguir, construiremos a tabela.

```{r}
volumes <- c(600, 700, 800, 900, 1000)
df <- data.frame(volume_usg = volumes)
previsto <- predict(ajuste, df, interval='confidence')
previsto <- data.frame(previsto)
intervalo <- previsto$fit - previsto$lwr
previsto <- cbind(volume_usg = volumes, peso = previsto$fit, intervalo = intervalo)
colnames(previsto) <- c("Volume", "Peso previsto", "Intervalo de confiança de 95%")
kable(previsto, caption="Pesos previstos pelo modelo")
```

vi)

vi)i)

Novamente, tomaremos o Volume USG como a variável explicativa x e o Peso Real como a variável resposta y. Adotaremos o modelo de regressão linear simples $y_i = \beta x_i + e_i$, onde $beta$ é a inclinação da reta e $e_i$ são erros aleatórias não correlacionados.

vi)ii)

```{r}
dados3 <- data.frame(dados1)
ggplot(dados3, aes(x=volume_usg, y=peso_real)) + geom_point() + labs(title=scatter_title, x=scatter_x, y=scatter_y)

```

vi)iii)

Realizaremos o ajuste do modelo e mostraremos algumas métricas de qualidade do modelo:

```{r, fig.height=4}
ajustarModelo <- function(dados) {
  # - 1 omite o intercepto
  ajuste <- lm(peso_real ~ volume_usg - 1, data=dados)
  intercept <- 0
  slope <- ajuste$coefficients
  print("O ajuste encontrou o coeficiente:")
  print(paste("Beta:", slope))
  p <- ggplot(dados, aes(x=volume_usg, y=peso_real)) + geom_point() + geom_abline(intercept = intercept, slope = slope) + labs(title=scatter_title, x=scatter_x, y=scatter_y)
  plot(p)
  print(summary(ajuste))
  plot(ajuste, caption=fit_titles)
  
  return(ajuste)
}

ajuste <- ajustarModelo(dados3)
```

Novamente, os gráficos indicam que a observação 15 é um outlier. Refaremos o ajuste removendo a observação 15.

```{r, fig.height=4}
dados4 <- dados1[-c(15), ]
ajuste <- ajustarModelo(dados4)
```

As mesmas observações sobre a qualidade do modelo se aplicam. Os gráficos indicam que os resíduos possuem os valores dentro do esperado. Idealmente, o R^2 deveria estar próximo de 1, mas não está. Dessa forma, podemos concluir que o ajuste do modelo aproxima os dados, mas não estritamente. Assim, espera-se que o intervalo de confiança ao prever o peso real com base no volume seja grande.

vi)iv)

Construindo intervalos de confiança dos parâmetros:

```{r}
confidence_intervals <- confint(ajuste)
rownames(confidence_intervals) <- c("Beta")
kable(confidence_intervals, caption="Intervalos de confiança para o ajuste dos parâmetros do modelo")
```

vi)v)

A seguir, construiremos a tabela.

```{r}
volumes <- c(600, 700, 800, 900, 1000)
df <- data.frame(volume_usg = volumes)
previsto <- predict(ajuste, df, interval='confidence')
previsto <- data.frame(previsto)
intervalo <- previsto$fit - previsto$lwr
previsto <- cbind(volume_usg = volumes, intervalo=previsto$fit, intervalo = intervalo)
colnames(previsto) <- c("Volume", "Peso previsto", "Intervalo de confiança de 95%")
kable(previsto, caption="Pesos previstos pelo modelo")
```

vi)vi)

Ambos os modelos satisfazem de forma similar as métricas mostradas na etapa (iii). Entretanto, observa-se na etapa (v) que o segundo modelo apresenta intervalos de confiança menores para suas predições de peso real. Dessa forma, o modelo sem intersecto demonstrou-se mais conveniente. Destacamos que o intervalo de confiança de 97,5% do parâmetro $\alpha$ no primeiro modelo era consideravelmente alto, o que poderia indicar que ele não possuia muita importância no modelo.

## Exercício 2

i) O valor $\alpha$, correspondente ao ponto onde a reta da regressão corta o eixo $y$ quando $x=0$, será nesse caso o valor médio dentre todas as médias das notas obtidas, tanto por alunos de escolas públicas quanto particulares. 
E $\beta$ corresponde a metade da diferença entre a média das médias dos alunos na escola particular e pública.

ii) Sejam $\hat{\alpha}$ e $\hat{\beta}$ estimativa para $\alpha$ e $\beta$ respectivamente, pelo Método dos Mínimos Quadrados temos:

```{r, echo=TRUE}
medias <- read_xlsx("data/medias_escolas.xlsx")
x <- medias$x
y <- medias$y

x_bar <- mean(x) 
y_bar <- mean(y)

beta_hat <- sum( (x-x_bar)*(y-y_bar) )/sum( (x-x_bar)^2 )
alpha_hat <- y_bar - beta_hat*x_bar
```

```{r, echo=FALSE}
print(paste("Alpha estimado: ", alpha_hat))
print(paste("Beta estimado: ", beta_hat))
```

Estimativa $S^2$ para $\sigma^2$:

```{r, echo=TRUE}
n = length(x)
y_pred <- alpha_hat + beta_hat*x
residuos <- y-y_pred
SQRes <- sum(residuos^2)
S2 <- SQRes/(n-2)
```

```{r, echo=FALSE}
print(paste("Variância estimada: ", S2))
```

```{r, echo=FALSE, fig.height=2, fig.width=5, fig.align='center'}
mediaescola <- transform(medias, tipo=factor(x))
ggplot(mediaescola) + aes(x = tipo, y = y, color=tipo) + 
  geom_point(size=2, pch=20) + 
  labs(title = "Desempenho", x = "x (Escola)", y = "y (Média)", color="Tipo de escola\n") + scale_color_manual(labels=c("Publica", "Particular"), values=c("blue", "red")) + 
  geom_abline(intercept = alpha_hat, slope = beta_hat, color="red") 

```

iii) Avalie a qualidade do modelo através de técnicas de diagnóstico

Através do coeficiênte de determinação:

```{r, echo= TRUE}
y_pred <- alpha_hat + beta_hat*x
SQTot <- sum( (y-y_bar)^2 )
SQRes <- sum( (y-y_pred)^2 )

R2 <- 1-SQRes/SQTot
```
```{r, echo=FALSE}
print(paste("Coeficiente R2: ", R2))
```
Vemos que o modelo proposto explica apenas 9% da variância dos dados, formando um ajuste ruim. 

```{r, echo=FALSE}
plot_titles <- list("Gráfico de Resíduos", 
                    "Gráfico Q-Q Normal", 
                    "Gráfico de Resíduos Padronizados",
                    "Distância de Cook")
```

```{r, echo=TRUE}
modelo <- lm(medias, formula = y~x)
par(mfrow = c(2,2))
plot(modelo, which=c(1:4), pch=19, caption=plot_titles)
```

Analisando o Gráfico de Cook temos os pontos alavanca destacados (7, 8 e 12), indicando que são os pontos de maior influência na estimação dos parâmetros. No gráfico de Resíduos Padronizados vemos na parte inferior outliers, que não aparecem nos demais gráficos, também nota-se que a variância dos dados é aparentemente uniforme com a variação da variável explicativa, sugerindo homocedastidade. Já no Gráfico Q-Q Normal os pontos visualmente se aproximam de uma linha reta, indicando que a distribuição das médias das notas apresenta comportamento similar ao da distribuição normal.

iv) Supondo que $e_i$ possui distribuição normal e não são correlacionados.

Usando que 

```{=latex}
\begin{equation*}
Var(\hat{\alpha}) = \sigma^2 \frac{\sum_{i=1}^{n}{x_i^2}}{n \sum_{i=1}^{n}(x_i-\bar{x})^2}
\end{equation*}
```

têm-se

```{r, echo=TRUE}
var_alpha <- S2*sum(x^2)/(n*sum((x-x_bar)^2))
delta_alpha <- 1.96*sqrt(var_alpha/n)
delta_alpha
```
Agora para $\hat{\beta}$, com:

```{=latex}
\begin{equation*}
Var(\hat{\beta}) = \frac{\sigma^2}{\sum_{i=1}^{n}{(x_i-\bar{x})^2}}
\end{equation*}
```

obtemos:

```{r, echo=TRUE}
var_beta <- S2/sum( (x-x_bar)^2 )
delta_beta <- 1.96*sqrt(var_beta/n)
delta_beta
```

Disso, os limites para os intervalos de confiança de 95% são:

```{=latex}
\begin{table}[ht]
\caption{Intervalo de confiança de 95\% para $\alpha$ e $\beta$}
\vspace*{0.5cm}
\centering
\begin{tabular}{c|ccc}
Parâmetro & Valor esperado & limite inferior & limite superior\\
\hline
$\alpha$ & 6.8556 & 6.7377 & 6.9734\\
$\beta$ & 0.3222 & 0.2043 & 0.4401\\
\hline
\end{tabular}
\end{table}

Obs.: os valores apresentados estão arredondados na quarta casa decimal.
```

v) Usando que o intervalo de 95% de confiança para a estimação das notas é:

```{=latex}
\begin{equation*}
\hat{y} \pm 1,96S\sqrt{\frac{1}{n}+\frac{(x_0+\bar{x})^2}{\sum_{i=1}^{n}{(x_i-\bar{x})^2}}}
\end{equation*}
```

temos:

```{r, echo=TRUE, fig.height=3, fig.width=6, fig.align='center'}
desvio <- sqrt(S2)
x_val = (-11:11)/10 #pontos intermediários para plotar o gráfico
y_val = alpha_hat + beta_hat*x_val
delta <- 1.96*desvio*sqrt(1/n+(x_val-x_bar)^2/sum((x_val-x_bar)^2))

upper = y_val+delta
lower = y_val-delta

plot(x, y)
title("Intervalo de Confiança")
abline(a = alpha_hat, b = beta_hat)
lines(x_val, upper, col="red")
lines(x_val, lower, col="red")

```
Quando $x_0 \in \{-1, 1\}$ com $\bar{x} = 0$ temos:

```{r, echo=TRUE}
delta <- 1.96*desvio*sqrt(1/n+1/sum(x^2))
delta
```
```{=latex}
\begin{table}[ht]
\caption{Intervalos de confiança de 95\% para o valor esperado das notas}
\vspace*{0.5cm}
\centering
\begin{tabular}{c|ccc}
Escola & $\hat{y}$ & limite inferior & limite superior\\
\hline
Particular & 7.178 & 6.4704 & 7.8851\\
Pública & 6.534 & 5.8260 & 7.2407\\
\hline
\end{tabular}
\end{table}

Obs.: os valores apresentados estão arredondados na quarta casa decimal.
```

vi) 

vii)

a) Nesse caso $\alpha$ é o valor de $y$ em $x=0$ da reta da regressão, ou seja, correspondente a média das médias dos alunos de escola pública. Já $\beta$ é a diferença entre a média das médias dos alunos de escola particular e pública.

b) Sendo $\hat{\alpha}$ e $\hat{\beta}$ estimativas de $\alpha$ e $\beta$ pelo Método de Mínimos Quadrados:

```{r, echo=TRUE}
medias <- read_xlsx("data/medias_escolas.xlsx")
medias[medias == -1] <- 0
x <- medias$x
y <- medias$y

x_bar <- mean(x)
y_bar <- mean(y)

beta_hat <- sum((x-x_bar)*(y-y_bar))/sum((x-x_bar)^2)
alpha_hat <- y_bar-beta_hat*x_bar
```

```{r, echo=FALSE}
print(paste("Alpha estimado: ", alpha_hat))
print(paste("Beta estimado:", beta_hat))
```

Estimativa $S^2$ para $\sigma^2$: 

```{r, echo=TRUE}
n = length(x)
y_pred <- alpha_hat+beta_hat*x
residuos <- y-y_pred
SQRes <- sum(residuos^2)
S2 <- 1/(n-2)*SQRes
```
```{r, echo=FALSE}
print(paste("Variância estimada: ", S2))
```

```{r, echo=FALSE, fig.height=2, fig.width=5, fig.align='center'}
dados <- transform(medias, tipo=factor(x))
ggplot(dados) + aes(x = tipo, y = y, color=tipo) + 
  geom_point(size=2, pch=20) + 
  labs(title = "Desempenho", x = "x (Escola)", y = "y (Média)", color="Tipo de escola\n") + scale_color_manual(labels=c("Publica", "Particular"), values=c("blue", "red")) + 
  geom_abline(intercept = alpha_hat, slope = beta_hat, color="red") 

```

c) Qualidade do ajuste


Através do coeficiênte de determinação:

```{r, echo= TRUE}
y_pred <- alpha_hat+beta_hat*x
SQTot <- sum((y-y_bar)^2)
SQRes <- sum((y-y_pred)^2)

R2 <- 1-SQRes/SQTot
```

```{r, echo=FALSE}
print(paste("Coeficiente R2: ", R2))
```
Obtemos o mesmo coeficiente de determinação que no item (iii), tendo, como antes, pouca explicação dos dados pelo modelo.

```{r, echo=TRUE}
modelo <- lm(medias, formula = y~x)
par(mfrow = c(2,2))
plot(modelo, which=c(1:4), pch=19, caption=plot_titles)
```

Assim como no item (iii), temos no Gráfico de Cook os mesmos pontos alavanca (7, 8 e 12), influenciando notavelmente na estimação dos parâmetros. No gráfico de Resíduos Padronizados vemos na parte inferior outliers em torno do valor 0.2, que não aparecem nos demais gráficos, ainda no Gráfico de Resíduos Padronizados notamos a homocedastidade. E o Gráfico Q-Q Normal sugere que a distribuição das médias das notas apresenta comportamento similar ao da distribuição normal.

d)  Analogamente ao item (iv), supondo que $e_i$ possui distribuição normal e não são correlacionados. Temos:

```{r, echo=TRUE}
var_alpha <- S2*sum(x^2)/(n*sum((x-x_bar)^2))
delta_alpha <- 1.96*sqrt(var_alpha/n)
delta_alpha
```

```{r, echo=TRUE}
var_beta <- S2/sum( (x-x_bar)^2 )
delta_beta <- 1.96*sqrt(var_beta/n)
delta_beta
```

Portanto, os limites para os intervalos de confiança de 95% são:

```{=latex}
\begin{table}[ht]
\caption{Intervalo de confiança de 95\% para $\alpha$ e $\beta$}
\vspace*{0.5cm}
\centering
\begin{tabular}{c|ccc}
Parâmetro & Valor esperado & limite inferior & limite superior\\
\hline
$\alpha$ & 6.5334 & 6.3667 & 6.7001\\
$\beta$ & 0.6444 & 0.4087 & 0.8802\\
\hline
\end{tabular}
\end{table}

Obs.: os valores apresentados estão arredondados na quarta casa decimal.
```


e) Usando que o intervalo de 95% de confiança para a estimação das notas é:

```{=latex}
\begin{equation*}
\hat{y} \pm 1,96S\sqrt{\frac{1}{n}+\frac{(x_0+\bar{x})^2}{\sum_{i=1}^{n}{(x_i-\bar{x})^2}}}
\end{equation*}
```

temos:

```{r, echo=TRUE, fig.height=3, fig.width=6, fig.align='center'}
desvio <- sqrt(S2)
x_val = (-1:21)/20 # pontos intermediários para plotar o gráfico
y_val = alpha_hat + beta_hat*x_val
delta <- 1.96*desvio*sqrt(1/n+(x_val-x_bar)^2/sum((x_val-x_bar)^2))

upper = y_val+delta
lower = y_val-delta

plot(x, y)
title("Intervalo de Confiança")
abline(a = alpha_hat, b = beta_hat)
lines(x_val, upper, col="red")
lines(x_val, lower, col="red")

```
Quando $x_0 \in \{-1, 1\}$ com $\bar{x} = 0$ temos:

```{r, echo=TRUE}
delta <- 1.96*desvio*sqrt(1/n+1/sum(x^2))
delta
```
```{=latex}
\begin{table}[ht]
\caption{Intervalos de confiança de 95\% para o valor esperado das notas}
\vspace*{0.5cm}
\centering
\begin{tabular}{c|ccc}
Escola & $\hat{y}$ & limite inferior & limite superior\\
\hline
Particular & 7.178 & 6.3114 & 8.0441\\
Pública & 6.534 & 5.6667 & 7.3997\\
\hline
\end{tabular}
\end{table}

Obs.: os valores apresentados estão arredondados na quarta casa decimal.
```

## Exercício 3
# i)
```{r}
imovel <- c("1",  "2",  "3",  "4" , "5",  "6"  ,"7" , "8" , "9" , "10", "11", "12", "13", "14")

area <- c(128 , 125,  200, 4000,  258,  360,  896,  400,  352,  250,  135, 6492, 1040, 3000)

preco <- c(10000,  9000,  17000, 200000,  25000,  40000,  70000,  25000,  35000,  27000,  11000, 120000,   
35000, 300000)

area <- as.numeric(resumo$area)
preco <- as.numeric(resumo$preco)
resumo <- cbind.data.frame(imovel, area, preco)

plot(resumo$area,resumo$preco)
```

# ii)
```{r}
mod <- lm(preco ~ area, data=resumo)

par(mfrow=c(2,2))
plot(mod)

summary(mod)

ggplot(data = resumo, mapping = aes(x = area, y=preco))+
  geom_point()+
  geom_smooth(method = "lm", col = "red")+
  theme_classic()

y = 31,011x + 26935
```

# iii)
```{r}
y = 52051ln(x) - 259408
R^2 = 0.642
```

# iv)
```{r}
predict(mod, data.frame(area = 200))
predict(mod, data.frame(area = 500))
predict(mod, data.frame(area = 1000))
```
## Exercício 4

## Exercício 15

a)
\begin{math}
\\SSE(\hat{\beta} ) = \sum_{i=1}^{n} \hat{e_{i}}^2 = \sum_{i=1}^{n} (y_{i}-\hat{\beta} x_{i})^2
\\
\\\cfrac {d SSE(\hat{\beta})} {d \hat{\beta}} =
  \sum_{i=1}^{n} 2(y_{i}-\hat{\beta} x_{i}) (-x_{i} )  = 
   -2\sum_{i=1}^{n}(y_{i}x_{i}-\hat{\beta} x_{i}^2) 
\\
\\ \cfrac {d SSE(\hat{\beta})} {d \hat{\beta}} = 
      -2\sum_{i=1}^{n} (y_{i}x_{i}) + 2\hat{\beta}\sum_{i=1}^{n}x_{i}^2 = 0 , \text{para minimizar}
\\
\\ 2\sum_{i=1}^{n} (y_{i}x_{i}) = 2\hat{\beta}\sum_{i=1}^{n}x_{i}^2 
\\
\\ \hat{\beta} = \cfrac { \sum_{i=1}^{n} (y_{i}x_{i}) } { \sum_{i=1}^{n}x_{i}^2 }
             = \cfrac {\sum_{i=1}^{n}  (y_{i}-\bar{y}) (x_{i}-\bar{x})}{ \sum_{i=1}^{n} (x_{i}-\bar{x})^2} 
\\
\\ \hat{\sigma}^2 = S^2 = \cfrac{1}{n-1}SSE(\beta)
\\
\\ S^2 = \cfrac{1}{n-1} \sum_{i=1}^{n} (y_{i}-\hat{\beta} x_{i}^2) 
\\
\end{math}

b)
\begin{math}
\\
\text{Para o modelo de regressão linear simples classico, onde }\\
\hat{e_{i}} \sim Normal( 0 , \sigma ^2 ) \text{ temos } \hat{\beta} \sim t - student(n-1)
\\
\end{math}

c)
\begin{math}
\\
\text{Sendo t para }  \gamma / 2 \text{ com n-1 graus de liberdade, temos: }
\\
IC(\beta) = \hat{\beta} \pm t\sqrt{S^2} 
          = \beta^2 \pm t \cfrac{\sum_{i=1}^{n}(y_{i}-\hat{\beta}x_{i})}{ \sqrt{n-1}}
\end{math}


## Exercício 16
